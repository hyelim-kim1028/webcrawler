{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목표: 1) 키워드를 ['힐링']으로 정해두고 이미지/제목/장소/태그 크롤해오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02cf9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo_code \n",
    "\n",
    "# HTML > 대한민국 구석구석 페이지 열기 \n",
    "\n",
    "# 검색키워드입력 \n",
    "  # words = [\"힐링\",\"여름\",\"산\"]\n",
    "  # for key in words: \n",
    "# 페이지 이동 \n",
    "\n",
    "# 힐링 \n",
    "# title \n",
    "# location \n",
    "# hashtag \n",
    "# time.sleep(2)\n",
    "\n",
    "# 페이지 넘기기 \n",
    "# 1~10 \n",
    "# for page in pages \n",
    "\n",
    "# csv 저장 pd로 저장 \n",
    "# 이미지 따로 저장 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e119a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromedriver_autoinstaller\n",
    "from selenium import webdriver\n",
    "\n",
    "# Error: WebDriverException: Message: Service chromedriver unexpectedly exited. Status code was: -6 \n",
    "# Reason: \n",
    "# solution: I thought this was because of the colab environment, so I moved from colab to jupyter ntb  \n",
    "\n",
    "# chromedriver-autoinstaller 이용\n",
    "chromedriver_autoinstaller.install(cwd=True)\n",
    "# HEADLESS MODE\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('headless')\n",
    "# options.binary_location = ('C:\\Program Files\\chromedriver.exe') #binary location # Chrome failed to start: was killed.\n",
    "options.add_argument('window-size=1920x1080')\n",
    "# options.add_argument(\"--disable-gpu\")\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "# options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "args = [\"hide_console\", ]\n",
    "# 알림창 끄기\n",
    "options.add_experimental_option(\"prefs\", {\"profile.default_content_setting_values.notifications\": 1})\n",
    "# 웹사이트 접속 후 해당 메뉴로 이동\n",
    "driver = webdriver.Chrome(options=options,service_args=args)\n",
    "driver.get(\"https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\")\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf40c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한가로이 걸으며 힐링 할 수 있는\\n화순 둘레길', '[소도시 낭만 여행, 마이리틀시티] 6탄\\n소소하지만 확실한 순창의 힐링 포인트 3', '한방으로 내 몸에 활기를 주는 힐링 체험, 제천 티테라', '사회 초년생에게도 힐링이 필요해', '넷플릭스 드라마 <괴물>의 촬영지,\\n힐링 가득 옥천의 반전 매력 스폿 5', '거닐며 힐링하며 즐기는 공중 산책로, 서울로 7017', '영주 가볼만한 곳. 느리게 걷는 영주, 당일치기 힐링여행 코스', '산꼭대기 예술 정원, 뮤지엄 산 <9월의 힐링콘서트>', '꽃, 나비와 숲속 힐링 타임,\\n국립제천치유의숲', '미술관과 아쿠아리움으로 떠나는 힐링 여행']\n",
      "['전라남도 화순군', '전라북도 순창군', '충청북도 제천시', '충청북도', '충청북도 옥천군', '서울 중구', '경상북도 영주시', '강원도 원주시', '충청북도 제천시', '서울 용산구']\n",
      "['#화순여행#화순가볼만한곳#너릿재공원#너릿재#세량지#화순8경#세량제#동구리호수공원#공원#호수공원#무등산편백자연휴양림#자연휴양림#산림욕장#화순둘레길#여행', '#순창여행#순창가볼만한곳#소도시여행#체험여행#힐링여행#힐링카페#로컬푸드#문화공간#드라이브여행#출렁다리#채계산#장군목유원지#공공누리#마이리틀시티', '#어르신추천코스#제천가볼만한곳#티테라#제천한방엑스포공원#능강솟대문화공간#산야초마을#약초생활건강#제천1박2일코스#무장애여행지#장애인추천여행지', '#힐링여행#체험여행#자연휴양림#생거진천자연휴양림#송호국민관광지#캠핑장#좌구산자연휴양림#베어트리파크', '#옥천여행#옥천가볼만한곳#힐링여행#드라마촬영지#부소담악#옥천성당#금강휴게소#만양정육점#괴물#옥천전통문화체험관#풍경여행#공공누리', '#서울가볼만한곳#도시재생#도심여행#걷기여행#힐링#주전부리여행#드라마촬영지#역사여행#서울맛집#서울로7017#아이와함께#체험학습#장미김밥#수국식빵#도토리풀빵', '#영주가볼만한곳#영주여행#힐링여행#무섬마을#외나무다리#부석사#희방폭포#소수서원#선비촌', '#원주가볼만한곳#뮤지엄산#미술관#전시관#힐링여행#걷기길#주말추천여행지', '#2020년8월추천가볼만한곳#8월추천가볼만한곳#추천가볼만한곳#8월가볼만한곳#힐링의숲#제천여행#제천가볼만한곳#공공누리', '#당일코스#1박2일#2박3일#가족코스#힐링코스#연인코스#간절기코스']\n"
     ]
    }
   ],
   "source": [
    "# reference: https://ltlkodae.tistory.com/18 \n",
    "\n",
    "#제목 \n",
    "# driver.find_elements_by_class_name('tit')\n",
    "# print([e.text for e in driver.find_elements_by_class_name('tit')[:10]]) \n",
    "# # 한페이지에 10개, 10개까지는 나옴 \n",
    "# # 다음 페이지로는 안나옴 \n",
    "\n",
    "# #장소 \n",
    "# # div.class = \"service\" #p \n",
    "# # driver.find_elements_by_class_name('service')\n",
    "# print([e.text for e in driver.find_elements_by_class_name('service')[:10] ])\n",
    "\n",
    "# #hashtags \n",
    "# #p class = \"tag_type\" <#span #em>\n",
    "# driver.find_elements_by_class_name('tag_type')\n",
    "# print([e.text for e in driver.find_elements_by_class_name('tag_type')[:10]])\n",
    "\n",
    "# things are returned by name/string > print()로 바꿔주기 \n",
    "\n",
    "\n",
    "\n",
    "# 한페이지에서 #find_elements를 사용하여 # list로 출력 \n",
    "\n",
    "print([e.text for e in driver.find_elements_by_class_name('tit')[:10]]) \n",
    "print([e.text for e in driver.find_elements_by_class_name('service')[:10]])\n",
    "print([e.text for e in driver.find_elements_by_class_name('tag_type')[:10]])\n",
    "\n",
    "#problems: 1) 페이지 넘기기 2) hashtags 정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89cd04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import selenium\n",
    "# # 검색버튼 id 값 \n",
    "# #div.class=\"tit\"\n",
    "# driver.find_element_by_class_name('tit').click()\n",
    "\n",
    "# # Error: WebDriverException: Message: chrome not reachable (Session info: chrome=91.0.4472.124)\n",
    "# # reason: \n",
    "# # solution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34bbb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import html\n",
    "# from urllib.request import urlopen \n",
    "# from bs4 import BeautifulSoup \n",
    "# import re \n",
    "\n",
    "# html = driver.page_source\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup.prettify()) # check if parser is working #O\n",
    "\n",
    "#제목 \n",
    "# div class = \"tit\" \n",
    "# fist trial: failed : HTML problem \n",
    "# titList = soup.findAll('span',{'class':'tit'}) \n",
    "# for title in titList:\n",
    "#     print(title.get_text())\n",
    "    \n",
    "# second trial: \n",
    "# titList = soup.findAll(class_ = 'tit')\n",
    "# for title in titList: \n",
    "#     print(title.text)\n",
    "# success # prob: no messy \n",
    "\n",
    "# #장소 \n",
    "# # div.class = \"service\" #p \n",
    "# locList = soup.findAll(class_='service')\n",
    "# for loc in locList: \n",
    "#     print(loc)\n",
    "# Error: SyntaxError: unexpected EOF while parsing\n",
    "\n",
    "# #hashtags \n",
    "# #p class = \"tag_type\" <#span #em>\n",
    "# tagzList = soup.findAll(class_ = 'tag_type') \n",
    "# for tagz in tagzList: \n",
    "#     print(tagz) \n",
    "# success # prob: no messy \n",
    "\n",
    "# Error: TypeError: object of type 'module' has no len()\n",
    "# reason:  \n",
    "# solution1: change to  soup = BeautifulSoup(html.text, 'html.parser') => did not work \n",
    "# AttributeError: module 'html' has no attribute 'text'\n",
    "\n",
    "# change of code trial: \n",
    "\n",
    "# import requests \n",
    "# from urllib.request import urlopen \n",
    "# from urllib import request \n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# URL = \"https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\"\n",
    "# response = requests.get(URL)\n",
    "# bs=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# even this code was returned with \n",
    "# TypeError: object of type 'module' has no len()\n",
    "\n",
    "# solution2: instead, I used (html, 'lxml')\n",
    "# does not work => WebDriverException: Message: chrome not reachable\n",
    "# version compatibility \n",
    "# source: https://stackoverflow.com/questions/49205782/selenium-common-exceptions-webdriverexception-message-chrome-not-reachable-err\n",
    "\n",
    "# solution 3: setting the binary location for chromedriver \n",
    "# it just killed the chrome \n",
    "\n",
    "# reason: I did not indicate what html is and I was trying to parse it \n",
    "# previous code \n",
    "# driver.page_source \n",
    "# soup = BeautifulSoup(html, 'html.parser') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f908925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup \n",
    "import re \n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "item_box = soup.findAll(class_ = 'box_leftType1')  #크롤링 구역 설정 \n",
    "\n",
    "# for item in item_box: \n",
    "#     print(item) #checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b51152aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'findAll'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-fb4bc66943c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# titList = soup.findAll(class_='tit')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtitList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# titList = soup.findAll('', {'class':'tit'})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2173\u001b[0m         raise AttributeError(\n\u001b[1;32m-> 2174\u001b[1;33m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'findAll'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "liList = soup.findAll('li')\n",
    "\n",
    "# for item in item_box: # item_box 내에서 아이템 나누기 \n",
    "#     print(item)\n",
    "\n",
    "# class = tit으로 크롤링해올경우, 필요없는 것까지 불러온다는 문제가 있다 \n",
    "# div class = tit a href em em br (O)\n",
    "# div class = tit h2 (X) \n",
    "    \n",
    "# titList = soup.findAll(class_='tit')\n",
    "titList = soup.findAll(class_='tit').findAll('a')\n",
    "print(titList)\n",
    "# titList = soup.findAll('', {'class':'tit'})\n",
    "# titList2 = soup.findAll('div', {'class':'tit'}).findAll('a')\n",
    "# titList = soup.findAll('div').findAll(class_='tit').findAll('a')\n",
    "\n",
    "# locList = soup.findAll(class_='service') # a안에 있는 tit만 가져오고 # h2에 있는 tit은 가져오면 안된다 \n",
    "# tagzList = soup.findAll(class_ = 'tag_type') \n",
    "\n",
    "\n",
    "\n",
    "# for i in item_box: # item_box 내에서 찾기 \n",
    "    \n",
    "#     for title in titList: \n",
    "#         print(title.txt) # 갑자기 다 None으로 됨 \n",
    "\n",
    "#     for loc in locList: \n",
    "#         print(loc.text)\n",
    "\n",
    "#     for tagz in tagzList: \n",
    "#         print(tagz.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 변수 생성 \n",
    "\n",
    "n = 0 #번호 시작점 생성 \n",
    "title = [] #제목 \n",
    "location = [] #장소 \n",
    "hashtagz = [] # 해쉬태그 \n",
    "file = 0 # 이미지 파일번호 시작점 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b197813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue: 페이지가 넘어가면서 url이 동일하다 \n",
    "# 페이지1: https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\n",
    "# 페이지2: https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\n",
    "# 페이지3: https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81 \n",
    "# reference: https://hodubab.tistory.com/246 \n",
    "\n",
    "# 번호가 없기 때문에 사용할 수 없다 \n",
    "\n",
    "# i = 1\n",
    "\n",
    "# while i<11: \n",
    "#     try: \n",
    "#         base_url = \n",
    "        \n",
    "#         driver \n",
    "#         titList = soup.findAll(class_='tit')\n",
    "# # titList = soup.findAll('', {'class':'tit'})\n",
    "# # titList2 = soup.findAll('div', {'class':'tit'}).findAll('a')\n",
    "# # titList = soup.findAll('div').findAll(class_='tit').findAll('a')\n",
    "#         locList = soup.findAll(class_='service')\n",
    "#         tagzList = soup.findAll(class_ = 'tag_type')\n",
    "        \n",
    "#         title \n",
    "#         print \n",
    "        \n",
    "#     # 필요 변수 생성 \n",
    "\n",
    "#     n = 0 #번호 시작점 생성 \n",
    "#     title = [] #제목 \n",
    "#     location = [] #장소 \n",
    "#     hashtagz = [] # 해쉬태그 \n",
    "#     file = 0 # 이미지 파일번호 시작점 설정 \n",
    "#     line = (base_url, title)\n",
    "    \n",
    "#     pd_csv \n",
    "    \n",
    "#     except: \n",
    "#         print('error')\n",
    "        \n",
    "#     i = i+1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한페이지에서 #find_elements를 사용하여 # list로 출력 \n",
    "\n",
    "print([e.text for e in driver.find_elements_by_class_name('tit')[:10]]) \n",
    "print([e.text for e in driver.find_elements_by_class_name('service')[:10]])\n",
    "print([e.text for e in driver.find_elements_by_class_name('tag_type')[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df522703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html><html lang=\"ko\"><head><title>HTTP 상태 405 – 허용되지 않는 메소드</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP 상태 405 – 허용되지 않는 메소드</h1><hr class=\"line\" /><p><b>타입</b> 상태 보고</p><p><b>메시지</b> Request method &#39;POST&#39; not supported</p><p><b>설명</b> 요청 행에 포함된 해당 메소드는, origin 서버에 의해 인지되었으나, 대상 리소스에 의해 지원되지 않습니다.</p><hr class=\"line\" /><h3>Apache Tomcat/8.5.57</h3></body></html>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f6f12ee1bef9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m         )\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare_headers\u001b[1;34m(self, headers)\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCaseInsensitiveDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 \u001b[1;31m# Raise exception on invalid header value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mcheck_header_validity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# POST 방식의 크롤링 \n",
    "# reference1: https://warm-uk.tistory.com/42\n",
    "# reference2: https://surgach.tistory.com/7\n",
    "# reference3: https://www.askcompany.kr/vod/crawling/146/\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "payload = {'key1':'value1', 'key2':'value2'}\n",
    "\n",
    "r = requests.post(\"https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\", data = payload)\n",
    "print(r.text)\n",
    "\n",
    "header = {'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "# header from: http://www.useragentstring.com/\n",
    "\n",
    "url = \"https://korean.visitkorea.or.kr/search/search_list.do?keyword=%ED%9E%90%EB%A7%81\"\n",
    "r = requests.get(url, headers = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d88bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28633aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3176196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8a422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d004c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b233f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd00d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d576e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0050b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bc2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2651999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68214e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d5cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6eec05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c79e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63368eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 결과 처리 \n",
    "\n",
    "# 데이터 프레임으로 변환 \n",
    "\n",
    "guseokX2 = pd.DataFrame()\n",
    "guseokX2['번호'] = pd.Series(n)\n",
    "guseokX2['제목'] = pd.Series(title)\n",
    "guseokX2['장소'] = pd.Series(location)\n",
    "guseokX2['해쉬테그'] = pd.Series(hashtagz)\n",
    "guseokX2['이미지 파일번호 시작점 설정'] = pd.Series(file)\n",
    "\n",
    "# csv 파일로 저장 \n",
    "guseokX2.to_csv(fc_name, encoding = \"utf-8-sig\", index = False) # customize \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
